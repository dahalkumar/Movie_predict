{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.movie_predictor.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from box.exceptions import BoxValueError\n",
    "import yaml\n",
    "from src.movie_predictor import logger\n",
    "import json\n",
    "import joblib\n",
    "from ensure import ensure_annotations\n",
    "from box import ConfigBox\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def read_yaml(path_to_yaml: Path) -> ConfigBox:\n",
    "    \"\"\"reads yaml file and returns\n",
    "    Args:\n",
    "        path_to_yaml (str): input is path\n",
    "    Raises:\n",
    "        ValueError: if yaml file is empty\n",
    "        e: empty file\n",
    "    Returns:\n",
    "        ConfigBox: ConfigBox type\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(path_to_yaml) as yaml_file:\n",
    "            config_yaml = yaml.safe_load(yaml_file)\n",
    "            logger.info(f\"yaml file: {path_to_yaml} loaded successfully\")\n",
    "            return ConfigBox(config_yaml)\n",
    "    except BoxValueError:\n",
    "        raise ValueError(\"yaml file is empty\")\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "@ensure_annotations\n",
    "def create_directories(path_to_directories: list, verbose=True):\n",
    "    \"\"\"create list of directories\n",
    "    Args:\n",
    "        path_to_directories (list): list of path of directories\n",
    "        ignore_log (bool, optional): ignore if multiple dirs is to be created. Defaults to False.\n",
    "    \"\"\"\n",
    "    for path in path_to_directories:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        if verbose:\n",
    "            logger.info(f\"created directory at: {path}\")\n",
    "\n",
    "@ensure_annotations\n",
    "def save_json(path: Path, data: dict):\n",
    "    \"\"\"save json data\n",
    "    Args:\n",
    "        path (Path): path to json file\n",
    "        data (dict): data to be saved in json file\n",
    "    \"\"\"\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "    logger.info(f\"json file saved at: {path}\")\n",
    "\n",
    "@ensure_annotations\n",
    "def load_json(path: Path) -> ConfigBox:\n",
    "    \"\"\"load json files data\n",
    "    Args:\n",
    "        path (Path): path to json file\n",
    "    Returns:\n",
    "        ConfigBox: data as class attributes instead of dict\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        config_yaml = json.load(f)\n",
    "\n",
    "    logger.info(f\"json file loaded succesfully from: {path}\")\n",
    "    return ConfigBox(config_yaml)\n",
    "\n",
    "@ensure_annotations\n",
    "def save_object(file_path:str,obj):\n",
    "    \"\"\"\n",
    "    file_path: str\n",
    "    obj: Any sort of object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dir_path = os.path.dirname(file_path)\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        with open(file_path, \"wb\") as file_obj:\n",
    "            joblib.dump(obj, file_obj)\n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "@ensure_annotations\n",
    "def load_bin(path: Path) -> Any:\n",
    "    \"\"\"load binary data\n",
    "    Args:\n",
    "        path (Path): path to binary file\n",
    "    Returns:\n",
    "        Any: object stored in the file\n",
    "    \"\"\"\n",
    "    data = joblib.load(path)\n",
    "    logger.info(f\"binary file loaded from: {path}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "@ensure_annotations\n",
    "def load_data(file_path: str, schema_file_path: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        datatset_schema = read_yaml(schema_file_path)\n",
    "\n",
    "        schema = datatset_schema[DATASET_SCHEMA_COLUMNS_KEY]\n",
    "\n",
    "        dataframe = pd.read_csv(file_path)\n",
    "\n",
    "        error_messgae = \"\"\n",
    "\n",
    "\n",
    "        for column in dataframe.columns:\n",
    "            if column in list(schema.keys()):\n",
    "                dataframe[column].astype(schema[column])\n",
    "            else:\n",
    "                error_messgae = f\"{error_messgae} \\nColumn: [{column}] is not in the schema.\"\n",
    "        if len(error_messgae) > 0:\n",
    "            raise Exception(error_messgae)\n",
    "        return dataframe\n",
    "\n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "@ensure_annotations\n",
    "def save_numpy_array_data(file_path: Path, array: np.array):\n",
    "    \"\"\"\n",
    "    Save numpy array data to file\n",
    "    file_path: str location of file to save\n",
    "    array: np.array data to save\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dir_path = os.path.dirname(file_path)\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        with open(file_path, 'wb') as file_obj:\n",
    "            np.save(file_obj, array)\n",
    "    except Exception as e:\n",
    "        return e\n",
    "        \n",
    "@ensure_annotations\n",
    "def get_size(path: Path) -> str:\n",
    "    \"\"\"get size in KB\n",
    "    Args:\n",
    "        path (Path): path of the file\n",
    "    Returns:\n",
    "        str: size in KB\n",
    "    \"\"\"\n",
    "    size_in_kb = round(os.path.getsize(path)/1024)\n",
    "    return f\"~ {size_in_kb} KB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformConfig:\n",
    "    root_dir: Path\n",
    "    tranfored_train_dir: Path\n",
    "    transormed_test_dir: Path\n",
    "    preprocessed_file_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(DATA_VALIDATION_FILE)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_data_transform_config(self) -> DataTransformConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories(config.root_dir)\n",
    "        create_directories(config.transformed_train_dir)\n",
    "        create_directories(config.transformed_test_dir)\n",
    "        create_directories(config.preprocessed_dir)\n",
    "\n",
    "        data_transform_config = DataTransformConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            tranfored_train_dir = config.transformed_train_dir,\n",
    "            transormed_test_dir = config.transformed_test_dir,\n",
    "            preprocessed_file_path = config.preprocessed_object_file_name\n",
    "        )\n",
    "        return data_transform_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "DataIngestionArtifact = namedtuple(\"DataIngestionArtifact\",\n",
    "[ \"train_file_path\", \"test_file_path\", \"is_ingested\", \"message\"])\n",
    "\n",
    "DataValidationArtifact = namedtuple(\"DataValidationArtifact\",\n",
    "[ \"report_file_path\",\"report_page_file_path\",\"is_validated\",\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SCHEMA_COLUMNS_KEY = \"columns\"\n",
    "NUMERICAL_COLUMN_KEY = \"numerical_columns\"\n",
    "CATEGORICAL_COLUMN_KEY = \"categorical_columns\"\n",
    "TARGET_COLUMN_KEY = \"target_column\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfigBox({'columns': {'Unnamed': 'Integer', 'originalTitle': 'category', 'domestic_revenue': 'category', 'distributor': 'category', 'opening_revenue': 'category', 'opening_theaters': 'category', 'budget': 'category', 'MPAA': 'category', 'genres_x': 'category', 'release_days': 'float', 'tconst': 'category', 'titleType': 'category', 'isAdult': 'Float', 'startYear': 'Integer', 'runtimeMinutes': 'category', 'genres_y': 'category', 'averageRating': 'float', 'numVotes': 'float', 'ordering': 'float', 'nconst': 'category', 'category': 'category', 'job': 'category', 'characters': 'category', 'primaryName': 'category', 'birthYear': 'category', 'deathYear': 'catgory', 'primaryProfession': 'category', 'knownForTitles': 'categoy', 'world_revenue': 'category'}, 'numerical_columns': {'Unnamed': 'Integer', 'release_days': 'float', 'isAdult': 'Float', 'startYear': 'Integer', 'averageRating': 'float', 'numVotes': 'float', 'ordering': 'float'}, 'categorical_columns': {'originalTitle': 'category', 'domestic_revenue': 'category', 'distributor': 'category', 'opening_revenue': 'category', 'opening_theaters': 'category', 'budget': 'category', 'MPAA': 'category', 'genres_x': 'category', 'tconst': 'category', 'titleType': 'category', 'runtimeMinutes': 'category', 'genres_y': 'category', 'nconst': 'category', 'category': 'category', 'job': 'category', 'characters': 'category', 'primaryName': 'category', 'birthYear': 'category', 'deathYear': 'catgory', 'primaryProfession': 'category', 'knownForTitles': 'categoy'}, 'target_column': 'world_revenue', 'domain_value': {'MPAA': '-PG-13, -R, -Not Rated, -G, -PG,'}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatset_schema = read_yaml(DATA_VALIDATION_FILE)\n",
    "datatset_schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Unnamed', 'originalTitle', 'domestic_revenue', 'distributor', 'opening_revenue', 'opening_theaters', 'budget', 'MPAA', 'genres_x', 'release_days', 'tconst', 'titleType', 'isAdult', 'startYear', 'runtimeMinutes', 'genres_y', 'averageRating', 'numVotes', 'ordering', 'nconst', 'category', 'job', 'characters', 'primaryName', 'birthYear', 'deathYear', 'primaryProfession', 'knownForTitles', 'world_revenue'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = datatset_schema[DATASET_SCHEMA_COLUMNS_KEY]\n",
    "schema.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     col1    col2     col3\n",
      "0  1000.0     6.0     11.0\n",
      "1     NaN     7.0     12.0\n",
      "2  2000.0     NaN      NaN\n",
      "3     3.0  8000.0      NaN\n",
      "4     4.0     NaN     13.0\n",
      "5     5.0     9.0  14000.0\n",
      "6     NaN    10.0     15.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "# Example DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'col1': ['1,000','\\\\N', '2,000$', '3', '4$', '5',np.NAN],\n",
    "    'col2': ['6', '7$','\\\\N', '8,000','\\\\N', '9', '10'],\n",
    "    'col3': ['11$', '12','\\\\N',np.NAN,'13', '14,000', '15']\n",
    "})\n",
    "\n",
    "# Define a custom transformer class to replace `,` and `$` characters and convert object data types to float for specific columns\n",
    "class ReplaceCharsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X[self.columns] = X[self.columns].applymap(self._replace_chars)\n",
    "        for col in self.columns:\n",
    "            if X[col].dtype == 'O' or X[col].dtype == 'float':\n",
    "                X[col].replace('\\\\N', np.nan, inplace=True)\n",
    "                \n",
    "            if col in ['col1','col2','col3','col4','col5','col']:\n",
    "                X[col] = pd.to_numeric(X[col], errors='coerce')    \n",
    "    \n",
    "        return X\n",
    "    \n",
    "    def _replace_chars(self, cell):\n",
    "        if isinstance(cell, str):\n",
    "            cell_str = str(cell)\n",
    "            cell_str = cell_str.replace(',', '').replace('$', '')\n",
    "            return cell_str\n",
    "        else:\n",
    "            return cell\n",
    "\n",
    "# Create a pipeline that applies the ReplaceCharsTransformer to the DataFrame for specific columns\n",
    "pipeline = Pipeline([\n",
    "    ('replace_chars', ReplaceCharsTransformer(columns=['col1','col2','col3'])),\n",
    "    ('passthrough', 'passthrough')\n",
    "])\n",
    "\n",
    "# Apply the pipeline to the DataFrame\n",
    "df = pipeline.fit_transform(df)\n",
    "\n",
    "# Confirm the data type conversion\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38311/3836456302.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['col1'] = pd.to_numeric(df['col1'].str.replace('[^\\d.]', ''), errors='coerce')\n",
      "/tmp/ipykernel_38311/3836456302.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['col2'] = pd.to_numeric(df['col2'].str.replace('[^\\d.]', ''), errors='coerce')\n",
      "/tmp/ipykernel_38311/3836456302.py:17: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['col3'] = pd.to_numeric(df['col3'].str.replace('[^\\d.]', ''), errors='coerce')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m split \u001b[39m=\u001b[39m StratifiedShuffleSplit(n_splits\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, test_size\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[39m# Perform the stratified sampling\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfor\u001b[39;00m train_index, test_index \u001b[39min\u001b[39;00m split\u001b[39m.\u001b[39msplit(df, df[\u001b[39m'\u001b[39m\u001b[39mcol3\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m     25\u001b[0m     strat_train_set \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[train_index]\n\u001b[1;32m     26\u001b[0m     strat_test_set \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[test_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:1689\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[1;32m   1660\u001b[0m \n\u001b[1;32m   1661\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1686\u001b[0m \u001b[39mto an integer.\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m-> 1689\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[1;32m   1690\u001b[0m     \u001b[39myield\u001b[39;00m train, test\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2078\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2076\u001b[0m class_counts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbincount(y_indices)\n\u001b[1;32m   2077\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mmin(class_counts) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m-> 2078\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2079\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe least populated class in y has only 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2080\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m member, which is too few. The minimum\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2081\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m number of groups for any class cannot\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2082\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m be less than 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2083\u001b[0m     )\n\u001b[1;32m   2085\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m<\u001b[39m n_classes:\n\u001b[1;32m   2086\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2087\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe train_size = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m should be greater or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2088\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mequal to the number of classes = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_train, n_classes)\n\u001b[1;32m   2089\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Create the dataframe\n",
    "df = pd.DataFrame({\n",
    "    'col1': ['1,000','\\\\N', '2,000$', '3', '4$', '5',np.NAN],\n",
    "    'col2': ['6', '7$','\\\\N', '8,000','\\\\N', '9', '10'],\n",
    "    'col3': ['11$', '12','\\\\N',np.NAN,'13', '14,000', '15']\n",
    "})\n",
    "\n",
    "# Convert col1 and col2 to numeric values\n",
    "df['col1'] = pd.to_numeric(df['col1'].str.replace('[^\\d.]', ''), errors='coerce')\n",
    "df['col2'] = pd.to_numeric(df['col2'].str.replace('[^\\d.]', ''), errors='coerce')\n",
    "\n",
    "# Convert col3 to numeric values and fill missing values with 0\n",
    "df['col3'] = pd.to_numeric(df['col3'].str.replace('[^\\d.]', ''), errors='coerce')\n",
    "df['col3'].fillna(0, inplace=True)\n",
    "\n",
    "# Create the StratifiedShuffleSplit object\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "\n",
    "# Perform the stratified sampling\n",
    "for train_index, test_index in split.split(df, df['col3']):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "\n",
    "# Print the sampled dataframes\n",
    "print(strat_train_set)\n",
    "print(strat_test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>domestic_revenue</th>\n",
       "      <th>world_revenue</th>\n",
       "      <th>distributor</th>\n",
       "      <th>opening_revenue</th>\n",
       "      <th>opening_theaters</th>\n",
       "      <th>budget</th>\n",
       "      <th>MPAA</th>\n",
       "      <th>genres_x</th>\n",
       "      <th>...</th>\n",
       "      <th>ordering</th>\n",
       "      <th>nconst</th>\n",
       "      <th>category</th>\n",
       "      <th>job</th>\n",
       "      <th>characters</th>\n",
       "      <th>primaryName</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>deathYear</th>\n",
       "      <th>primaryProfession</th>\n",
       "      <th>knownForTitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Super 30</td>\n",
       "      <td>$2,269,878</td>\n",
       "      <td>24701637</td>\n",
       "      <td>Reliance Big Pictures</td>\n",
       "      <td>$871,256</td>\n",
       "      <td>317.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Biography,Drama</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm0618898</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sajid Nadiadwala</td>\n",
       "      <td>1966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>producer,writer,director</td>\n",
       "      <td>tt7518786tt2372222tt8366590tt7721946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ad Astra</td>\n",
       "      <td>$50,188,370</td>\n",
       "      <td>127461872</td>\n",
       "      <td>Twentieth Century Fox</td>\n",
       "      <td>$19,001,398</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>90000000.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>Adventure,Drama,Mystery,Sci-Fi,Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm1250070</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeremy Kleiner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>producer,miscellaneous</td>\n",
       "      <td>tt2024544tt1020072tt4975722tt7125860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Art of Self-Defense</td>\n",
       "      <td>$2,410,914</td>\n",
       "      <td>2414269</td>\n",
       "      <td>Bleecker Street Media</td>\n",
       "      <td>$114,374</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>Action,Comedy,Crime,Drama,Mystery,Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm3442546</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stephanie Whonsetler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>production_manager,miscellaneous,producer</td>\n",
       "      <td>tt6269368tt10962368tt7339248tt4595186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Welcome to Marwen</td>\n",
       "      <td>$10,763,520</td>\n",
       "      <td>13061491</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>$2,354,205</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>Biography,Comedy,Drama,Fantasy,Romance</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm0823330</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steve Starkey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>producer,assistant_director,editorial_department</td>\n",
       "      <td>tt0109830tt0118884tt1907668tt0162222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Welcome to Marwen</td>\n",
       "      <td>$10,763,520</td>\n",
       "      <td>13061491</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>$2,354,205</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>Biography,Comedy,Drama,Fantasy,Romance</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm0823330</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steve Starkey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>producer,assistant_director,editorial_department</td>\n",
       "      <td>tt0109830tt0118884tt1907668tt0162222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            originalTitle domestic_revenue  world_revenue  \\\n",
       "0           0                 Super 30       $2,269,878       24701637   \n",
       "1           1                 Ad Astra      $50,188,370      127461872   \n",
       "2           2  The Art of Self-Defense       $2,410,914        2414269   \n",
       "3           3        Welcome to Marwen      $10,763,520       13061491   \n",
       "4           4        Welcome to Marwen      $10,763,520       13061491   \n",
       "\n",
       "             distributor opening_revenue  opening_theaters      budget   MPAA  \\\n",
       "0  Reliance Big Pictures        $871,256             317.0         NaN    NaN   \n",
       "1  Twentieth Century Fox     $19,001,398            3460.0  90000000.0  PG-13   \n",
       "2  Bleecker Street Media        $114,374               7.0         NaN      R   \n",
       "3     Universal Pictures      $2,354,205            1911.0         NaN  PG-13   \n",
       "4     Universal Pictures      $2,354,205            1911.0         NaN  PG-13   \n",
       "\n",
       "                                     genres_x  ...  ordering     nconst  \\\n",
       "0                             Biography,Drama  ...         9  nm0618898   \n",
       "1     Adventure,Drama,Mystery,Sci-Fi,Thriller  ...         9  nm1250070   \n",
       "2  Action,Comedy,Crime,Drama,Mystery,Thriller  ...         9  nm3442546   \n",
       "3      Biography,Comedy,Drama,Fantasy,Romance  ...         9  nm0823330   \n",
       "4      Biography,Comedy,Drama,Fantasy,Romance  ...         9  nm0823330   \n",
       "\n",
       "   category       job  characters           primaryName birthYear  deathYear  \\\n",
       "0  producer  producer         NaN      Sajid Nadiadwala      1966        NaN   \n",
       "1  producer  producer         NaN        Jeremy Kleiner       NaN        NaN   \n",
       "2  producer  producer         NaN  Stephanie Whonsetler       NaN        NaN   \n",
       "3  producer  producer         NaN         Steve Starkey       NaN        NaN   \n",
       "4  producer  producer         NaN         Steve Starkey       NaN        NaN   \n",
       "\n",
       "                                  primaryProfession  \\\n",
       "0                          producer,writer,director   \n",
       "1                            producer,miscellaneous   \n",
       "2         production_manager,miscellaneous,producer   \n",
       "3  producer,assistant_director,editorial_department   \n",
       "4  producer,assistant_director,editorial_department   \n",
       "\n",
       "                          knownForTitles  \n",
       "0   tt7518786tt2372222tt8366590tt7721946  \n",
       "1   tt2024544tt1020072tt4975722tt7125860  \n",
       "2  tt6269368tt10962368tt7339248tt4595186  \n",
       "3   tt0109830tt0118884tt1907668tt0162222  \n",
       "4   tt0109830tt0118884tt1907668tt0162222  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "# Example DataFrame\n",
    "df = pd.read_csv('main.csv')\n",
    "\n",
    "# Define a custom transformer class to replace `,` and `$` characters and convert object data types to float for specific columns\n",
    "class ReplaceCharsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X[self.columns] = X[self.columns].applymap(self._replace_chars)\n",
    "        for col in self.columns:\n",
    "            if X[col].dtype == 'O' or X[col].dtype == 'float':\n",
    "                X[col].replace('\\\\N', np.nan, inplace=True)\n",
    "                \n",
    "            if col in ['budget','opening_theaters','world_revenue','runtimeMinutes']:\n",
    "                X[col] = pd.to_numeric(X[col], errors='coerce')    \n",
    "    \n",
    "        return X\n",
    "    \n",
    "    def _replace_chars(self, cell):\n",
    "        if isinstance(cell, str):\n",
    "            cell_str = str(cell)\n",
    "            cell_str = cell_str.replace(',', '').replace('$', '')\n",
    "            return cell_str\n",
    "        else:\n",
    "            return cell\n",
    "\n",
    "# Create a pipeline that applies the ReplaceCharsTransformer to the DataFrame for specific columns\n",
    "pipeline = Pipeline([\n",
    "    ('replace_chars', ReplaceCharsTransformer(columns=['budget','opening_theaters','world_revenue','runtimeMinutes','genres_y','job','characters','birthYear','deathYear','knownForTitles'])),\n",
    "    ('passthrough', 'passthrough')\n",
    "])\n",
    "\n",
    "# Apply the pipeline to the DataFrame\n",
    "df = pipeline.fit_transform(df)\n",
    "\n",
    "# Confirm the data type conversion\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_new_line_null(feature):\n",
    "    if '\\\\N' in df.values :    \n",
    "        if (df[feature] == '\\\\N').sum()>0:\n",
    "            count_n = (df[feature] == '\\\\N').sum().sum()\n",
    "            \n",
    "            print(feature,count_n)\n",
    "\n",
    "        \n",
    "for feature in df.columns:\n",
    "    check_new_line_null(feature)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "class ReplaceCharsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X[self.columns] = X[self.columns].applymap(self._replace_chars)\n",
    "        for col in self.columns:\n",
    "            if X[col].dtype == 'O' or X[col].dtype == 'float':\n",
    "                X[col].replace('\\\\N', np.nan, inplace=True)\n",
    "                \n",
    "            if col in ['budget','opening_theaters','world_revenue','runtimeMinutes']:\n",
    "                X[col] = pd.to_numeric(X[col], errors='coerce')    \n",
    "    \n",
    "        return X\n",
    "    \n",
    "    def _replace_chars(self, cell):\n",
    "        if isinstance(cell, str):\n",
    "            cell_str = str(cell)\n",
    "            cell_str = cell_str.replace(',', '').replace('$', '')\n",
    "            return cell_str\n",
    "        else:\n",
    "            return cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class FillMissingBudgets(TransformerMixin):\n",
    "    def __init__(self, df3):\n",
    "        self.d_p = dict(zip(df3['originalTitle'], df3['budget']))\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X['budget'] = X['budget'].fillna(X['originalTitle'].map(self.d_p))\n",
    "        return X\n",
    "\n",
    "class FillnaTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column, dictionary):\n",
    "        self.column = column\n",
    "        self.dictionary = dictionary\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X[self.column] = X[self.column].fillna(X['tconst'].map(self.dictionary))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "class DataTransform:\n",
    "    def __init__(self, data_transformation: DataTransformConfig,\n",
    "                 data_ingestion_artifact: DataIngestionArtifact,\n",
    "                 data_validation_artifact: DataValidationArtifact) -> None:\n",
    "        try:\n",
    "            \n",
    "            self.data_transformation_config = data_transformation\n",
    "            self.data_ingestion_artifact = data_ingestion_artifact\n",
    "            self.data_validation_artifact = data_validation_artifact\n",
    "\n",
    "        except Exception as e:\n",
    "            return e\n",
    "        \n",
    "    \n",
    "\n",
    "    def load_data(file_path: str) -> pd.DataFrame:\n",
    "        try:\n",
    "            # reading the schema_validation.yaml file\n",
    "            datatset_schema = read_yaml(DATA_VALIDATION_FILE)\n",
    "\n",
    "            # extracting the columns info from the schema file\n",
    "            schema = datatset_schema[DATASET_SCHEMA_COLUMNS_KEY]\n",
    "\n",
    "            # reading the dataset \n",
    "            dataframe = pd.read_csv(file_path)\n",
    "            error_messgae = \"\"\n",
    "            for column in dataframe.columns:\n",
    "                if column in list(schema.keys()):\n",
    "                    dataframe[column].astype(schema[column])\n",
    "                else:\n",
    "                    error_messgae = f\"{error_messgae} \\nColumn: [{column}] is not in the schema.\"\n",
    "            if len(error_messgae) > 0:\n",
    "                raise Exception(error_messgae)\n",
    "            return dataframe\n",
    "        except Exception as e:\n",
    "            return e \n",
    "        \n",
    "    \n",
    "    def get_data_transformer_object(self,dataframe)->ColumnTransformer:\n",
    "            try:\n",
    "                # train_file_path = self.data_ingestion_artifact.train_file_path\n",
    "                # test_file_path = self.data_ingestion_artifact.test_file_path\n",
    "                \n",
    "                datatset_schema = read_yaml(DATA_VALIDATION_FILE)\n",
    "                df1 = pd.read_excel('data__.xlsx',sheet_name='runtime')\n",
    "                df2 = pd.read_excel('data__.xlsx',sheet_name='opening_theaters')\n",
    "                df3 = pd.read_excel('manual_data.xlsx')\n",
    "                d = dict(zip(df2['tconst'], df2['opening_theaters']))\n",
    "                p = dict(zip(df1['tconst'], df1['runtimeMinutes']))\n",
    "                \n",
    "                                \n",
    "                # Create a pipeline that applies the ReplaceCharsTransformer to the DataFrame for specific columns\n",
    "                conversion_pipeline = Pipeline([\n",
    "                    ('replace_chars', ReplaceCharsTransformer(columns=['budget','opening_theaters','world_revenue','runtimeMinutes','genres_y','job','characters','birthYear','deathYear','knownForTitles'])),\n",
    "                    ('passthrough', 'passthrough')\n",
    "                ])\n",
    "                mpaa_missing_pipeline = Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "                ])\n",
    "                \n",
    "\n",
    "                manual_nan_pipeline = Pipeline([\n",
    "                    ('fillna_runtime', FillnaTransformer(column='runtimeMinutes', dictionary=d)),\n",
    "                    ('fillna_opening', FillnaTransformer(column='opening_theaters', dictionary=p)),\n",
    "                    ('fill_budgets', FillMissingBudgets(df3))\n",
    "                ])\n",
    "\n",
    "                df = conversion_pipeline.fit_transform(dataframe)\n",
    "                df['MPAA'] = mpaa_missing_pipeline.fit_transform(df[['MPAA']])\n",
    "\n",
    "                new_df = manual_nan_pipeline.fit_transform(df)\n",
    "\n",
    "                return new_df\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "            \n",
    "            except Exception as e:\n",
    "                return e    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "class ReplaceCharsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X[self.columns] = X[self.columns].applymap(self._replace_chars)\n",
    "        for col in self.columns:\n",
    "            if X[col].dtype == 'O' or X[col].dtype == 'float':\n",
    "                X[col].replace('\\\\N', np.nan, inplace=True)\n",
    "                \n",
    "            if col in ['budget','opening_theaters','world_revenue','runtimeMinutes']:\n",
    "                X[col] = pd.to_numeric(X[col], errors='coerce')    \n",
    "    \n",
    "        return X\n",
    "    \n",
    "    def _replace_chars(self, cell):\n",
    "        if isinstance(cell, str):\n",
    "            cell_str = str(cell)\n",
    "            cell_str = cell_str.replace(',', '').replace('$', '')\n",
    "            return cell_str\n",
    "        else:\n",
    "            return cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>domestic_revenue</th>\n",
       "      <th>world_revenue</th>\n",
       "      <th>distributor</th>\n",
       "      <th>opening_revenue</th>\n",
       "      <th>opening_theaters</th>\n",
       "      <th>budget</th>\n",
       "      <th>MPAA</th>\n",
       "      <th>genres_x</th>\n",
       "      <th>...</th>\n",
       "      <th>ordering</th>\n",
       "      <th>nconst</th>\n",
       "      <th>category</th>\n",
       "      <th>job</th>\n",
       "      <th>characters</th>\n",
       "      <th>primaryName</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>deathYear</th>\n",
       "      <th>primaryProfession</th>\n",
       "      <th>knownForTitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Super 30</td>\n",
       "      <td>$2,269,878</td>\n",
       "      <td>24701637</td>\n",
       "      <td>Reliance Big Pictures</td>\n",
       "      <td>$871,256</td>\n",
       "      <td>317.0</td>\n",
       "      <td>24701637.0</td>\n",
       "      <td>R</td>\n",
       "      <td>Biography,Drama</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm0618898</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sajid Nadiadwala</td>\n",
       "      <td>1966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>producer,writer,director</td>\n",
       "      <td>tt7518786tt2372222tt8366590tt7721946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ad Astra</td>\n",
       "      <td>$50,188,370</td>\n",
       "      <td>127461872</td>\n",
       "      <td>Twentieth Century Fox</td>\n",
       "      <td>$19,001,398</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>90000000.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>Adventure,Drama,Mystery,Sci-Fi,Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm1250070</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeremy Kleiner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>producer,miscellaneous</td>\n",
       "      <td>tt2024544tt1020072tt4975722tt7125860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Art of Self-Defense</td>\n",
       "      <td>$2,410,914</td>\n",
       "      <td>2414269</td>\n",
       "      <td>Bleecker Street Media</td>\n",
       "      <td>$114,374</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2414269.0</td>\n",
       "      <td>R</td>\n",
       "      <td>Action,Comedy,Crime,Drama,Mystery,Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm3442546</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stephanie Whonsetler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>production_manager,miscellaneous,producer</td>\n",
       "      <td>tt6269368tt10962368tt7339248tt4595186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Welcome to Marwen</td>\n",
       "      <td>$10,763,520</td>\n",
       "      <td>13061491</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>$2,354,205</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>13061491.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>Biography,Comedy,Drama,Fantasy,Romance</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm0823330</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steve Starkey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>producer,assistant_director,editorial_department</td>\n",
       "      <td>tt0109830tt0118884tt1907668tt0162222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Welcome to Marwen</td>\n",
       "      <td>$10,763,520</td>\n",
       "      <td>13061491</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>$2,354,205</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>13061491.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>Biography,Comedy,Drama,Fantasy,Romance</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm0823330</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steve Starkey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>producer,assistant_director,editorial_department</td>\n",
       "      <td>tt0109830tt0118884tt1907668tt0162222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            originalTitle domestic_revenue  world_revenue  \\\n",
       "0           0                 Super 30       $2,269,878       24701637   \n",
       "1           1                 Ad Astra      $50,188,370      127461872   \n",
       "2           2  The Art of Self-Defense       $2,410,914        2414269   \n",
       "3           3        Welcome to Marwen      $10,763,520       13061491   \n",
       "4           4        Welcome to Marwen      $10,763,520       13061491   \n",
       "\n",
       "             distributor opening_revenue  opening_theaters      budget   MPAA  \\\n",
       "0  Reliance Big Pictures        $871,256             317.0  24701637.0      R   \n",
       "1  Twentieth Century Fox     $19,001,398            3460.0  90000000.0  PG-13   \n",
       "2  Bleecker Street Media        $114,374               7.0   2414269.0      R   \n",
       "3     Universal Pictures      $2,354,205            1911.0  13061491.0  PG-13   \n",
       "4     Universal Pictures      $2,354,205            1911.0  13061491.0  PG-13   \n",
       "\n",
       "                                     genres_x  ...  ordering     nconst  \\\n",
       "0                             Biography,Drama  ...         9  nm0618898   \n",
       "1     Adventure,Drama,Mystery,Sci-Fi,Thriller  ...         9  nm1250070   \n",
       "2  Action,Comedy,Crime,Drama,Mystery,Thriller  ...         9  nm3442546   \n",
       "3      Biography,Comedy,Drama,Fantasy,Romance  ...         9  nm0823330   \n",
       "4      Biography,Comedy,Drama,Fantasy,Romance  ...         9  nm0823330   \n",
       "\n",
       "   category       job  characters           primaryName birthYear  deathYear  \\\n",
       "0  producer  producer         NaN      Sajid Nadiadwala      1966        NaN   \n",
       "1  producer  producer         NaN        Jeremy Kleiner       NaN        NaN   \n",
       "2  producer  producer         NaN  Stephanie Whonsetler       NaN        NaN   \n",
       "3  producer  producer         NaN         Steve Starkey       NaN        NaN   \n",
       "4  producer  producer         NaN         Steve Starkey       NaN        NaN   \n",
       "\n",
       "                                  primaryProfession  \\\n",
       "0                          producer,writer,director   \n",
       "1                            producer,miscellaneous   \n",
       "2         production_manager,miscellaneous,producer   \n",
       "3  producer,assistant_director,editorial_department   \n",
       "4  producer,assistant_director,editorial_department   \n",
       "\n",
       "                          knownForTitles  \n",
       "0   tt7518786tt2372222tt8366590tt7721946  \n",
       "1   tt2024544tt1020072tt4975722tt7125860  \n",
       "2  tt6269368tt10962368tt7339248tt4595186  \n",
       "3   tt0109830tt0118884tt1907668tt0162222  \n",
       "4   tt0109830tt0118884tt1907668tt0162222  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define a custom transformer that wraps the drop_duplicates method\n",
    "class DropDuplicatesTransformer(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.drop_duplicates()\n",
    "\n",
    "pipeline_duplicate = Pipeline([\n",
    "    ('remove_duplicates', DropDuplicatesTransformer())\n",
    "])\n",
    "\n",
    "# Apply the pipeline to the dataframe\n",
    "df_clean = pipeline_duplicate.fit_transform(df)\n",
    "\n",
    "# Print the result\n",
    "df_clean.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n",
      "4    David   40      Chicago\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define a custom transformer that wraps the drop_duplicates method\n",
    "class DropDuplicatesTransformer(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.drop_duplicates()\n",
    "\n",
    "# Create a sample dataframe with duplicate rows\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'David'],\n",
    "        'Age': [25, 30, 35, 25, 40],\n",
    "        'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Chicago']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the pipeline with the custom transformer\n",
    "pipeline = Pipeline([\n",
    "    ('remove_duplicates', DropDuplicatesTransformer())\n",
    "])\n",
    "\n",
    "# Apply the pipeline to the dataframe\n",
    "df_clean = pipeline.fit_transform(df)\n",
    "\n",
    "# Print the result\n",
    "print(df_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>world_revenue</th>\n",
       "      <th>distributor</th>\n",
       "      <th>opening_theaters</th>\n",
       "      <th>budget</th>\n",
       "      <th>MPAA</th>\n",
       "      <th>genres_x</th>\n",
       "      <th>release_days</th>\n",
       "      <th>startYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>ordering</th>\n",
       "      <th>category</th>\n",
       "      <th>primaryName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super 30</td>\n",
       "      <td>24701637</td>\n",
       "      <td>Reliance Big Pictures</td>\n",
       "      <td>317.0</td>\n",
       "      <td>24701637.0</td>\n",
       "      <td>R</td>\n",
       "      <td>Biography,Drama</td>\n",
       "      <td>173</td>\n",
       "      <td>2019</td>\n",
       "      <td>154.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>33523</td>\n",
       "      <td>9</td>\n",
       "      <td>producer</td>\n",
       "      <td>Sajid Nadiadwala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ad Astra</td>\n",
       "      <td>127461872</td>\n",
       "      <td>Twentieth Century Fox</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>90000000.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>Adventure,Drama,Mystery,Sci-Fi,Thriller</td>\n",
       "      <td>105</td>\n",
       "      <td>2019</td>\n",
       "      <td>123.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>239699</td>\n",
       "      <td>9</td>\n",
       "      <td>producer</td>\n",
       "      <td>Jeremy Kleiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Art of Self-Defense</td>\n",
       "      <td>2414269</td>\n",
       "      <td>Bleecker Street Media</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2414269.0</td>\n",
       "      <td>R</td>\n",
       "      <td>Action,Comedy,Crime,Drama,Mystery,Thriller</td>\n",
       "      <td>173</td>\n",
       "      <td>2019</td>\n",
       "      <td>104.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>38502</td>\n",
       "      <td>9</td>\n",
       "      <td>producer</td>\n",
       "      <td>Stephanie Whonsetler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Welcome to Marwen</td>\n",
       "      <td>13061491</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>13061491.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>Biography,Comedy,Drama,Fantasy,Romance</td>\n",
       "      <td>376</td>\n",
       "      <td>2018</td>\n",
       "      <td>116.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>24570</td>\n",
       "      <td>9</td>\n",
       "      <td>producer</td>\n",
       "      <td>Steve Starkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Welcome to Marwen</td>\n",
       "      <td>13061491</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>13061491.0</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>Biography,Comedy,Drama,Fantasy,Romance</td>\n",
       "      <td>376</td>\n",
       "      <td>2018</td>\n",
       "      <td>116.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>24570</td>\n",
       "      <td>9</td>\n",
       "      <td>producer</td>\n",
       "      <td>Steve Starkey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             originalTitle  world_revenue            distributor  \\\n",
       "0                 Super 30       24701637  Reliance Big Pictures   \n",
       "1                 Ad Astra      127461872  Twentieth Century Fox   \n",
       "2  The Art of Self-Defense        2414269  Bleecker Street Media   \n",
       "3        Welcome to Marwen       13061491     Universal Pictures   \n",
       "4        Welcome to Marwen       13061491     Universal Pictures   \n",
       "\n",
       "   opening_theaters      budget   MPAA  \\\n",
       "0             317.0  24701637.0      R   \n",
       "1            3460.0  90000000.0  PG-13   \n",
       "2               7.0   2414269.0      R   \n",
       "3            1911.0  13061491.0  PG-13   \n",
       "4            1911.0  13061491.0  PG-13   \n",
       "\n",
       "                                     genres_x  release_days  startYear  \\\n",
       "0                             Biography,Drama           173       2019   \n",
       "1     Adventure,Drama,Mystery,Sci-Fi,Thriller           105       2019   \n",
       "2  Action,Comedy,Crime,Drama,Mystery,Thriller           173       2019   \n",
       "3      Biography,Comedy,Drama,Fantasy,Romance           376       2018   \n",
       "4      Biography,Comedy,Drama,Fantasy,Romance           376       2018   \n",
       "\n",
       "   runtimeMinutes  averageRating  numVotes  ordering  category  \\\n",
       "0           154.0            7.9     33523         9  producer   \n",
       "1           123.0            6.5    239699         9  producer   \n",
       "2           104.0            6.6     38502         9  producer   \n",
       "3           116.0            6.2     24570         9  producer   \n",
       "4           116.0            6.2     24570         9  producer   \n",
       "\n",
       "            primaryName  \n",
       "0      Sajid Nadiadwala  \n",
       "1        Jeremy Kleiner  \n",
       "2  Stephanie Whonsetler  \n",
       "3         Steve Starkey  \n",
       "4         Steve Starkey  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "class DropDuplicatesTransformer(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.drop_duplicates()\n",
    "class FillMissingBudgets(TransformerMixin):\n",
    "    def __init__(self, df3):\n",
    "        self.d_p = dict(zip(df3['originalTitle'], df3['budget']))\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X['budget'] = X['budget'].fillna(X['originalTitle'].map(self.d_p))\n",
    "        return X\n",
    "\n",
    "\n",
    "\n",
    "class FillnaTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column, dictionary):\n",
    "        self.column = column\n",
    "        self.dictionary = dictionary\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X[self.column] = X[self.column].fillna(X['tconst'].map(self.dictionary))\n",
    "        return X    \n",
    "\n",
    "\n",
    "class DropColumnsTransformer(TransformerMixin):\n",
    "    \"\"\"Custom transformer to drop columns from a Pandas DataFrame.\"\"\"\n",
    "    \n",
    "    def __init__(self, columns_to_drop):\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X = X.drop(columns=self.columns_to_drop)\n",
    "        return X\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "# Dictionaries to fill null values\n",
    "df3 = pd.read_excel('budget.xlsx')\n",
    "df1 = pd.read_excel('combine.xlsx',sheet_name='runtime')\n",
    "df2 = pd.read_excel('combine.xlsx',sheet_name='opening_theaters')\n",
    "d = dict(zip(df2['tconst'], df2['opening_theaters']))\n",
    "p = dict(zip(df1['tconst'], df1['runtimeMinutes']))\n",
    "\n",
    "# Define a custom transformer class to fill null values based on a dictionary\n",
    "# Create a pipeline that applies the FillnaTransformer to fill null values in two columns\n",
    "# Create a pipeline that applies the ReplaceCharsTransformer to the DataFrame for specific columns\n",
    "pipeline_duplicate = Pipeline([\n",
    "    ('remove_duplicates', DropDuplicatesTransformer())\n",
    "])\n",
    "\n",
    "# Apply the pipeline to the dataframe\n",
    "\n",
    "conversion_pipeline = Pipeline([\n",
    "                    ('replace_chars', ReplaceCharsTransformer(columns=['budget','opening_theaters','world_revenue','runtimeMinutes','genres_y','job','characters','birthYear','deathYear','knownForTitles'])),\n",
    "                    ('passthrough', 'passthrough')\n",
    "])\n",
    "mpaa_missing_pipeline = Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "                \n",
    "manual_nan_pipeline = Pipeline([\n",
    "                    ('fillna_runtime', FillnaTransformer(column='runtimeMinutes', dictionary=p)),\n",
    "                    ('fillna_opening', FillnaTransformer(column='opening_theaters', dictionary=d)),\n",
    "                    ('fill_budgets', FillMissingBudgets(df3))\n",
    "])\n",
    "cols_drop = ['Unnamed: 0','genres_y','domestic_revenue','opening_revenue','nconst','deathYear','job','characters','birthYear','primaryProfession','knownForTitles','isAdult','titleType','tconst']\n",
    "pipeline = Pipeline([\n",
    "    ('drop_cols', DropColumnsTransformer(columns_to_drop=cols_drop))\n",
    "])  \n",
    "df = pd.read_csv('main.csv')\n",
    "\n",
    "df_clean = pipeline_duplicate.fit_transform(df)\n",
    "df_clean = conversion_pipeline.fit_transform(df_clean)\n",
    "df_clean['MPAA'] = mpaa_missing_pipeline.fit_transform(df_clean[['MPAA']])\n",
    "\n",
    "new_df = manual_nan_pipeline.fit_transform(df_clean)\n",
    "transformed_df = pipeline.fit_transform(new_df)\n",
    "\n",
    "# Print the head of the DataFrame to confirm the changes\n",
    "transformed_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "originalTitle       0\n",
       "world_revenue       0\n",
       "distributor         0\n",
       "opening_theaters    6\n",
       "budget              0\n",
       "MPAA                0\n",
       "genres_x            0\n",
       "release_days        0\n",
       "startYear           0\n",
       "runtimeMinutes      0\n",
       "averageRating       0\n",
       "numVotes            0\n",
       "ordering            0\n",
       "category            0\n",
       "primaryName         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "transformed_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.labels_ordered_ = {}\n",
    "        categorical_features = [feature for feature in X.columns if X[feature].dtype == 'O']\n",
    "        for feature in categorical_features:\n",
    "            labels_ordered = X.groupby([feature]).size().sort_values().index\n",
    "            labels_ordered = {value: index for index, value in enumerate(labels_ordered, 0)}\n",
    "            self.labels_ordered_[feature] = labels_ordered\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        for feature, labels_ordered in self.labels_ordered_.items():\n",
    "            X[feature] = X[feature].map(labels_ordered)\n",
    "        return X.dropna()\n",
    "\n",
    "# Create the pipeline\n",
    "new_pipeline = Pipeline([\n",
    "    ('encoder', CategoricalEncoder()),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# Fit and transform the data\n",
    "coded = new_pipeline.fit_transform(transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.25000000e-02, 8.76942783e-03, 3.94495413e-01, ...,\n",
       "        1.00000000e+00, 1.00000000e+00, 3.99481193e-01],\n",
       "       [8.07180851e-01, 4.54788780e-02, 8.99082569e-01, ...,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.42671855e-01],\n",
       "       [7.84574468e-02, 8.07622132e-04, 9.17431193e-01, ...,\n",
       "        1.00000000e+00, 1.00000000e+00, 2.72373541e-01],\n",
       "       ...,\n",
       "       [9.08244681e-01, 1.23819442e-02, 6.97247706e-01, ...,\n",
       "        1.00000000e+00, 7.00000000e-01, 2.77561608e-01],\n",
       "       [9.08244681e-01, 1.23819442e-02, 6.97247706e-01, ...,\n",
       "        1.00000000e+00, 6.00000000e-01, 3.92996109e-01],\n",
       "       [8.37765957e-02, 9.94185282e-02, 1.00000000e+00, ...,\n",
       "        3.75000000e-01, 5.00000000e-01, 5.35667964e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_scale=[feature for feature in coded.columns if feature not in ['world_revenue']]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "\n",
    "scaler.fit(coded[feature_scale])\n",
    "\n",
    "data = pd.concat([coded[['world_revenue']].reset_index(drop=True),\n",
    "                    pd.DataFrame(scaler.transform(coded[feature_scale]), columns=feature_scale)],\n",
    "                    axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_revenue</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>distributor</th>\n",
       "      <th>opening_theaters</th>\n",
       "      <th>budget</th>\n",
       "      <th>MPAA</th>\n",
       "      <th>genres_x</th>\n",
       "      <th>release_days</th>\n",
       "      <th>startYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>ordering</th>\n",
       "      <th>category</th>\n",
       "      <th>primaryName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24701637</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.394495</td>\n",
       "      <td>0.01585</td>\n",
       "      <td>0.005729</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.228228</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>0.025749</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.399481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127461872</td>\n",
       "      <td>0.807181</td>\n",
       "      <td>0.899083</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.020880</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.027211</td>\n",
       "      <td>0.126126</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>0.184138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2414269</td>\n",
       "      <td>0.078457</td>\n",
       "      <td>0.917431</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.353741</td>\n",
       "      <td>0.228228</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.393333</td>\n",
       "      <td>0.607595</td>\n",
       "      <td>0.029574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13061491</td>\n",
       "      <td>0.849734</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.09555</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>0.533033</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.473333</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.835279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13061491</td>\n",
       "      <td>0.849734</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.09555</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>0.533033</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.473333</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.835279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   world_revenue  originalTitle  distributor  opening_theaters    budget  \\\n",
       "0       24701637       0.062500     0.394495           0.01585  0.005729   \n",
       "1      127461872       0.807181     0.899083           0.17300  0.020880   \n",
       "2        2414269       0.078457     0.917431           0.00035  0.000558   \n",
       "3       13061491       0.849734     1.000000           0.09555  0.003028   \n",
       "4       13061491       0.849734     1.000000           0.09555  0.003028   \n",
       "\n",
       "   MPAA  genres_x  release_days  startYear  runtimeMinutes  averageRating  \\\n",
       "0  1.00  0.976190      0.228228       0.25        0.726667       0.772152   \n",
       "1  0.75  0.027211      0.126126       0.25        0.520000       0.594937   \n",
       "2  1.00  0.353741      0.228228       0.25        0.393333       0.607595   \n",
       "3  0.75  0.602041      0.533033       0.00        0.473333       0.556962   \n",
       "4  0.75  0.602041      0.533033       0.00        0.473333       0.556962   \n",
       "\n",
       "   numVotes  ordering  category  primaryName  \n",
       "0  0.025749       1.0       1.0     0.399481  \n",
       "1  0.184138       1.0       1.0     0.142672  \n",
       "2  0.029574       1.0       1.0     0.272374  \n",
       "3  0.018871       1.0       1.0     0.835279  \n",
       "4  0.018871       1.0       1.0     0.835279  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataTransformationArtifact = namedtuple(\"DataTransformationArtifact\",\n",
    " [\"is_transformed\", \"message\", \"transformed_train_file_path\",\"transformed_test_file_path\",\n",
    "     \"preprocessed_object_file_path\"])\n",
    "class DataTransform:\n",
    "    def __init__(self, data_transformation: DataTransformConfig,\n",
    "                 data_ingestion_artifact: DataIngestionArtifact,\n",
    "                 data_validation_artifact: DataValidationArtifact) -> None:\n",
    "        try:\n",
    "            \n",
    "            self.data_transformation_config = data_transformation\n",
    "            self.data_ingestion_artifact = data_ingestion_artifact\n",
    "            self.data_validation_artifact = data_validation_artifact\n",
    "\n",
    "        except Exception as e:\n",
    "            return e\n",
    "        \n",
    "    def run_data_transformation(self)->DataTransformationArtifact:\n",
    "        try:\n",
    "            \n",
    "            preprocessing_obj = self.get_data_transformer_object()\n",
    "\n",
    "            #logging.info(f\"Obtaining training and test file path.\")\n",
    "            train_file_path = self.data_ingestion_artifact.train_file_path\n",
    "            test_file_path = self.data_ingestion_artifact.test_file_path\n",
    "            \n",
    "\n",
    "            #schema_file_path = self.data_validation_artifact.schema_file_path\n",
    "            datatset_schema = read_yaml(DATA_VALIDATION_FILE)\n",
    "            # logging.info(f\"Loading training and test data as pandas dataframe.\")\n",
    "            train_df = load_data(file_path=train_file_path, schema_file_path=datatset_schema)\n",
    "            \n",
    "            test_df = load_data(file_path=test_file_path, schema_file_path=datatset_schema)\n",
    "\n",
    "            schema = read_yaml(file_path=datatset_schema)\n",
    "\n",
    "            target_column_name = schema[TARGET_COLUMN_KEY]\n",
    "\n",
    "\n",
    "            #logging.info(f\"Splitting input and target feature from training and testing dataframe.\")\n",
    "            input_feature_train_df = train_df.drop(columns=[target_column_name],axis=1)\n",
    "            target_feature_train_df = train_df[target_column_name]\n",
    "\n",
    "            input_feature_test_df = test_df.drop(columns=[target_column_name],axis=1)\n",
    "            target_feature_test_df = test_df[target_column_name]\n",
    "            \n",
    "\n",
    "            #logging.info(f\"Applying preprocessing object on training dataframe and testing dataframe\")\n",
    "            input_feature_train_arr=preprocessing_obj.fit_transform(input_feature_train_df)\n",
    "            input_feature_test_arr = preprocessing_obj.transform(input_feature_test_df)\n",
    "\n",
    "\n",
    "            train_arr = np.c_[ input_feature_train_arr, np.array(target_feature_train_df)]\n",
    "\n",
    "            test_arr = np.c_[input_feature_test_arr, np.array(target_feature_test_df)]\n",
    "            # root_dir: Path\n",
    "            # tranfored_train_dir: Path\n",
    "            # transormed_test_dir: Path\n",
    "            # preprocessed_file_path: Path\n",
    "            transformed_train_dir = self.data_transformation_config.tranfored_train_dir\n",
    "            transformed_test_dir = self.data_transformation_config.transormed_test_dir\n",
    "            #since we have numpy array data we replace file extension in npz\n",
    "            train_file_name = os.path.basename(train_file_path).replace(\".csv\",\".npz\")\n",
    "            test_file_name = os.path.basename(test_file_path).replace(\".csv\",\".npz\")\n",
    "\n",
    "            transformed_train_file_path = os.path.join(transformed_train_dir, train_file_name)\n",
    "            transformed_test_file_path = os.path.join(transformed_test_dir, test_file_name)\n",
    "\n",
    "            #logging.info(f\"Saving transformed training and testing array.\")\n",
    "            \n",
    "            save_numpy_array_data(file_path=transformed_train_file_path,array=train_arr)\n",
    "            save_numpy_array_data(file_path=transformed_test_file_path,array=test_arr)\n",
    "\n",
    "            preprocessing_obj_file_path = self.data_transformation_config.preprocessed_file_path\n",
    "\n",
    "            logging.info(f\"Saving preprocessing object.\")\n",
    "            save_object(file_path=preprocessing_obj_file_path,obj=preprocessing_obj)\n",
    "\n",
    "            data_transformation_artifact = DataTransformationArtifact(is_transformed=True,\n",
    "            message=\"Data transformation successfull.\",\n",
    "            transformed_train_file_path=transformed_train_file_path,\n",
    "            transformed_test_file_path=transformed_test_file_path,\n",
    "            preprocessed_object_file_path=preprocessing_obj_file_path\n",
    "\n",
    "            )\n",
    "            logging.info(f\"Data transformationa artifact: {data_transformation_artifact}\")\n",
    "            return data_transformation_artifact\n",
    "        except Exception as e:\n",
    "            return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.labels_ordered_ = {}\n",
    "        categorical_features = [feature for feature in X.columns if X[feature].dtype == 'O']\n",
    "        for feature in categorical_features:\n",
    "            labels_ordered = X.groupby([feature]).size().sort_values().index\n",
    "            labels_ordered = {value: index for index, value in enumerate(labels_ordered, 0)}\n",
    "            self.labels_ordered_[feature] = labels_ordered\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        for feature, labels_ordered in self.labels_ordered_.items():\n",
    "            X[feature] = X[feature].map(labels_ordered)\n",
    "        return X.dropna()\n",
    "\n",
    "all_columns = dataset_schema[DATASET_SCHEMA_COLUMNS_KEY]\n",
    "encoding_scaling_pipeline = Pipeline([\n",
    "                    ('encoder', CategoricalEncoder()),\n",
    "                     ('scaler', \n",
    "                      )\n",
    "            ])\n",
    "preprocessing = ColumnTransformer([\n",
    "            ('encoding_scaling_pipeline', encoding_scaling_pipeline, all_columns)\n",
    "\n",
    "            ])\n",
    "\n",
    "error message: encoding_scaling_pipeline [not enough values to unpack (expected 2, got 1)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Mar  1 2023, 18:23:06) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df8635527aba43c0978661b8f3d9ea7dfe51393f6f96b3dcf9d26e89056f8639"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
