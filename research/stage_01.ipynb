{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34martifacts\u001b[0m/     logistic_regression_scratch.ipynb  setup.cfg\n",
      "\u001b[01;34mbuild\u001b[0m/         \u001b[01;34mlogs\u001b[0m/                              setup.py\n",
      "\u001b[01;34mconfigs\u001b[0m/       params.yaml                        \u001b[01;34msrc\u001b[0m/\n",
      "\u001b[01;34mdist\u001b[0m/          pyproject.toml                     template.py\n",
      "dvc.yaml       README.md                          \u001b[01;34mtests\u001b[0m/\n",
      "\u001b[01;34menv\u001b[0m/           requirements_dev.txt               tox.ini\n",
      "init_setup.sh  requirements.txt\n",
      "LICENSE        \u001b[01;34mresearch\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.movie_predictor.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from box.exceptions import BoxValueError\n",
    "import yaml\n",
    "from src.movie_predictor import logger\n",
    "import json\n",
    "import joblib\n",
    "from ensure import ensure_annotations\n",
    "from box import ConfigBox\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "def read_yaml(path_to_yaml: Path) -> ConfigBox:\n",
    "    \"\"\"reads yaml file and returns\n",
    "    Args:\n",
    "        path_to_yaml (str): input is path\n",
    "    Raises:\n",
    "        ValueError: if yaml file is empty\n",
    "        e: empty file\n",
    "    Returns:\n",
    "        ConfigBox: ConfigBox type\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(path_to_yaml) as yaml_file:\n",
    "            config_yaml = yaml.safe_load(yaml_file)\n",
    "            logger.info(f\"yaml file: {path_to_yaml} loaded successfully\")\n",
    "            return ConfigBox(config_yaml)\n",
    "    except BoxValueError:\n",
    "        raise ValueError(\"yaml file is empty\")\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "@ensure_annotations\n",
    "def create_directories(path_to_directories: list, verbose=True):\n",
    "    \"\"\"create list of directories\n",
    "    Args:\n",
    "        path_to_directories (list): list of path of directories\n",
    "        ignore_log (bool, optional): ignore if multiple dirs is to be created. Defaults to False.\n",
    "    \"\"\"\n",
    "    for path in path_to_directories:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        if verbose:\n",
    "            logger.info(f\"created directory at: {path}\")\n",
    "\n",
    "@ensure_annotations\n",
    "def save_json(path: Path, data: dict):\n",
    "    \"\"\"save json data\n",
    "    Args:\n",
    "        path (Path): path to json file\n",
    "        data (dict): data to be saved in json file\n",
    "    \"\"\"\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "    logger.info(f\"json file saved at: {path}\")\n",
    "\n",
    "@ensure_annotations\n",
    "def load_json(path: Path) -> ConfigBox:\n",
    "    \"\"\"load json files data\n",
    "    Args:\n",
    "        path (Path): path to json file\n",
    "    Returns:\n",
    "        ConfigBox: data as class attributes instead of dict\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        config_yaml = json.load(f)\n",
    "\n",
    "    logger.info(f\"json file loaded succesfully from: {path}\")\n",
    "    return ConfigBox(config_yaml)\n",
    "\n",
    "@ensure_annotations\n",
    "def save_bin(data: Any, path: Path):\n",
    "    \"\"\"save binary file\n",
    "    Args:\n",
    "        data (Any): data to be saved as binary\n",
    "        path (Path): path to binary file\n",
    "    \"\"\"\n",
    "    joblib.dump(value=data, filename=path)\n",
    "    logger.info(f\"binary file saved at: {path}\")\n",
    "\n",
    "@ensure_annotations\n",
    "def load_bin(path: Path) -> Any:\n",
    "    \"\"\"load binary data\n",
    "    Args:\n",
    "        path (Path): path to binary file\n",
    "    Returns:\n",
    "        Any: object stored in the file\n",
    "    \"\"\"\n",
    "    data = joblib.load(path)\n",
    "    logger.info(f\"binary file loaded from: {path}\")\n",
    "    return data\n",
    "\n",
    "@ensure_annotations\n",
    "def get_size(path: Path) -> str:\n",
    "    \"\"\"get size in KB\n",
    "    Args:\n",
    "        path (Path): path of the file\n",
    "    Returns:\n",
    "        str: size in KB\n",
    "    \"\"\"\n",
    "    size_in_kb = round(os.path.getsize(path)/1024)\n",
    "    return f\"~ {size_in_kb} KB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    zip_data_file: Path\n",
    "    unzip_dir: Path\n",
    "    ingested_train_dir: Path\n",
    "    ingested_test_dir: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        self.schema = read_yaml(DATA_VALIDATION_FILE)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "        create_directories([config.ingested_train_dir])\n",
    "        create_directories([config.ingested_test_dir])\n",
    "        \n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            source_URL = config.source_URL,\n",
    "            zip_data_file = config.zip_data_file,\n",
    "            unzip_dir = config.unzip_dir,\n",
    "            ingested_train_dir = config.ingested_train_dir,\n",
    "            ingested_test_dir = config.ingested_test_dir\n",
    "        )\n",
    "\n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_read = read_yaml(CONFIG_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artifacts'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml_read.artifacts_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artifacts'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml_read.artifacts_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfigBox({'root_dir': 'artifacts/data_ingestion', 'source_URL': 'https://github.com/roshikdahal/movie_prediction/raw/main/research/movie.tgz', 'zip_data_file': 'artifacts/data_ingestion/raw_data', 'unzip_dir': 'artifacts/data_ingestion/local_data', 'ingested_train_dir': 'artifacts/data_ingestion/train', 'ingested_test_dir': 'artifacts/data_ingestion/test'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml_read.data_ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataIngestionConfig(root_dir='artifacts/data_ingestion', source_URL='https://github.com/roshikdahal/movie_prediction/raw/main/research/movie.tgz', zip_data_file='artifacts/data_ingestion/raw_data', unzip_dir='artifacts/data_ingestion/local_data', ingested_train_dir='artifacts/data_ingestion/train', ingested_test_dir='artifacts/data_ingestion/test')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = yaml_read.data_ingestion\n",
    "DataIngestionConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            source_URL = config.source_URL,\n",
    "            zip_data_file = config.zip_data_file,\n",
    "            unzip_dir = config.unzip_dir,\n",
    "            ingested_train_dir = config.ingested_train_dir,\n",
    "            ingested_test_dir = config.ingested_test_dir\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "DataIngestionArtifact = namedtuple(\"DataIngestionArtifact\",\n",
    "[ \"train_file_path\", \"test_file_path\", \"is_ingested\", \"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import tarfile\n",
    "import urllib.request as request\n",
    "class DataIngestion:\n",
    "    \n",
    "    def __init__(self,dataingestionconfig:DataIngestionConfig):\n",
    "        try:\n",
    "            \n",
    "            self.data_ingestion_config = dataingestionconfig\n",
    "        except Exception as e:\n",
    "            return e\n",
    "\n",
    "    def download_Movies_data(self,) -> str:\n",
    "        \"\"\"\n",
    "        this function get the url create the folder and store the downloaded data \n",
    "        in the folder which will be our zip folder.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data_url  =self.data_ingestion_config.source_URL\n",
    "            tgz_download_dir = self.data_ingestion_config.zip_data_file\n",
    "            os.makedirs(tgz_download_dir,exist_ok=True)\n",
    "\n",
    "            #create the folder name based on url base name\n",
    "            movie_file = os.path.basename(tgz_download_dir)\n",
    "            #now append the movie filename in download_dir\n",
    "            total_file_path = os.path.join(tgz_download_dir,movie_file)\n",
    "\n",
    "            start_time=time.time()\n",
    "            request.urlretrieve(data_url, total_file_path)\n",
    "            stop_time = time.time()\n",
    "            return total_file_path\n",
    "\n",
    "        except Exception as e:\n",
    "            return e\n",
    "\n",
    "    #since we have downloaded data and store it in total_file_path which is of extension tgz we need to unzip it and store in raw data\n",
    "    def extract_zip_file(self,total_file_path:str):\n",
    "        try:\n",
    "            raw_folder = self.data_ingestion_config.unzip_dir\n",
    "            #create the folder is exists is True also\n",
    "            os.makedirs(raw_folder,exist_ok=True)   \n",
    "\n",
    "            with tarfile.open(total_file_path) as movies_file_object:\n",
    "                movies_file_object.extractall(path=raw_folder)\n",
    "        except Exception as e:\n",
    "            return e\n",
    "\n",
    "    \n",
    "    def train_test_split(self)-> DataIngestionArtifact:\n",
    "            \"\"\"\n",
    "            spliting data into train test and appending it on data ingestion artifact_entity\n",
    "            \"\"\"\n",
    "            try:\n",
    "                raw_data = self.data_ingestion_config.unzip_dir\n",
    "                # #pick the first folder and get the data from first file \n",
    "                #main_folder= os.listdir(raw_data)[0]\n",
    "                # #now merge folder to get propoer file path\n",
    "                # movies_file_path = os.path.join(raw_data,main_folder)\n",
    "                # logging.info(\"Reading the movies csv file [{raw_data}]\")\n",
    "                #read the csv file\n",
    "                file_name = os.listdir(raw_data)[0]\n",
    "                movies_file_path = os.path.join(raw_data,file_name)\n",
    "                movies_df =  pd.read_csv(movies_file_path)\n",
    "                \n",
    "                #remaining to perform data split using stratified sampling\n",
    "\n",
    "                #logging.info(f\"Reading csv file: [{movies_file_path}]\")\n",
    "                #since world_revenue is our dependent variable we seprate the array element into bins and perform statistical analysis\n",
    "                movies_df['world_revenue'] = movies_df.world_revenue.str.replace('$','',regex=True)\n",
    "                movies_df['world_revenue'] = movies_df.world_revenue.str.replace(',','',regex=True)\n",
    "                movies_df['world_revenue'] =  pd.to_numeric(movies_df['world_revenue'], errors='coerce')\n",
    "                movies_df[\"revenue_cat\"] = pd.cut(\n",
    "                    movies_df[\"world_revenue\"],\n",
    "                    bins=[0.0, 1.5, 3.0, 4.5, 6.0, np.inf],  #category for our world revenue 0.0 and 1.5 one group 1.5 to 3.0 another\n",
    "                    labels=[1,2,3,4,5]  #names\n",
    "                )\n",
    "                \n",
    "\n",
    "                # logging.info(f\"Splitting data into train and test\")\n",
    "                strat_train_set = None\n",
    "                strat_test_set = None\n",
    "                #we are using StratifiedShuffleSplit to create  split with the size of 80:20 and n_splits is \n",
    "                # number of times the data needs to be sampled for test_size and data's are taken randomly at 42 \n",
    "                split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "                #our group is movies_df[\"income_cat\"] so split function will split based on this category\n",
    "                for train_index,test_index in split.split(movies_df, movies_df[\"revenue_cat\"]):\n",
    "                    #since only for split we use movies_df[\"income_cat\"] we are droping from train and test split\n",
    "                    strat_train_set = movies_df.loc[train_index].drop([\"revenue_cat\"],axis=1)\n",
    "                    strat_test_set = movies_df.loc[test_index].drop([\"revenue_cat\"],axis=1)\n",
    "\n",
    "                #for saving the strat_train_set and strat_test_set we have directory and our filename\n",
    "       \n",
    "                train_file_path = os.path.join(self.data_ingestion_config.ingested_train_dir,\n",
    "                                            file_name)\n",
    "\n",
    "                test_file_path = os.path.join(self.data_ingestion_config.ingested_test_dir,\n",
    "                                                        file_name)\n",
    "                \n",
    "    \n",
    "                if strat_train_set is not None:\n",
    "                    os.makedirs(self.data_ingestion_config.ingested_train_dir,exist_ok=True)\n",
    "                    #logging.info(f\"Exporting training datset to file: [{train_file_path}]\")\n",
    "                    strat_train_set.to_csv(train_file_path,index=False)\n",
    "\n",
    "                if strat_test_set is not None:\n",
    "                    os.makedirs(self.data_ingestion_config.ingested_test_dir, exist_ok= True)\n",
    "                    #logging.info(f\"Exporting test dataset to file: [{test_file_path}]\")\n",
    "                    strat_test_set.to_csv(test_file_path,index=False)\n",
    "                \n",
    "\n",
    "                data_ingestion_artifact = DataIngestionArtifact(train_file_path=train_file_path,\n",
    "                test_file_path=test_file_path,\n",
    "                is_ingested=True,\n",
    "                message=f\"Data ingestion completed successfully.\"\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "                # logging.info(f\"Data Ingestion artifact:[{data_ingestion_artifact}]\")\n",
    "                return data_ingestion_artifact\n",
    "\n",
    "            except Exception as e:\n",
    "                return e            \n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = ConfigurationManager()\n",
    "data_ingestion_config = config.get_data_ingestion_config()\n",
    "data_ingestion = DataIngestion(dataingestionconfig = data_ingestion_config)\n",
    "tgz_file = data_ingestion.download_Movies_data()\n",
    "data_ingestion.extract_zip_file(total_file_path = tgz_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataIngestionArtifact(train_file_path='artifacts/data_ingestion/train/main.csv', test_file_path='artifacts/data_ingestion/test/main.csv', is_ingested=True, message='Data ingestion completed successfully.')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ingestion.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = data_ingestion_config.unzip_dir\n",
    "file_name = os.listdir(raw_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_file_path = os.path.join(raw_data,file_name)\n",
    "movies_df =  pd.read_csv(movies_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>domestic_revenue</th>\n",
       "      <th>world_revenue</th>\n",
       "      <th>distributor</th>\n",
       "      <th>opening_revenue</th>\n",
       "      <th>opening_theaters</th>\n",
       "      <th>budget</th>\n",
       "      <th>MPAA</th>\n",
       "      <th>genres_x</th>\n",
       "      <th>...</th>\n",
       "      <th>ordering</th>\n",
       "      <th>nconst</th>\n",
       "      <th>category</th>\n",
       "      <th>job</th>\n",
       "      <th>characters</th>\n",
       "      <th>primaryName</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>deathYear</th>\n",
       "      <th>primaryProfession</th>\n",
       "      <th>knownForTitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Super 30</td>\n",
       "      <td>$2,269,878</td>\n",
       "      <td>$24,701,637</td>\n",
       "      <td>Reliance Big Pictures</td>\n",
       "      <td>$871,256</td>\n",
       "      <td>317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Biography,Drama</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm0618898</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Sajid Nadiadwala</td>\n",
       "      <td>1966</td>\n",
       "      <td>\\N</td>\n",
       "      <td>producer,writer,director</td>\n",
       "      <td>tt7518786,tt2372222,tt8366590,tt7721946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ad Astra</td>\n",
       "      <td>$50,188,370</td>\n",
       "      <td>$127,461,872</td>\n",
       "      <td>Twentieth Century Fox</td>\n",
       "      <td>$19,001,398</td>\n",
       "      <td>3,460</td>\n",
       "      <td>$90,000,000</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>Adventure,Drama,Mystery,Sci-Fi,Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm1250070</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Jeremy Kleiner</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>producer,miscellaneous</td>\n",
       "      <td>tt2024544,tt1020072,tt4975722,tt7125860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Art of Self-Defense</td>\n",
       "      <td>$2,410,914</td>\n",
       "      <td>$2,414,269</td>\n",
       "      <td>Bleecker Street Media</td>\n",
       "      <td>$114,374</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>Action,Comedy,Crime,Drama,Mystery,Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm3442546</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Stephanie Whonsetler</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>production_manager,miscellaneous,producer</td>\n",
       "      <td>tt6269368,tt10962368,tt7339248,tt4595186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Welcome to Marwen</td>\n",
       "      <td>$10,763,520</td>\n",
       "      <td>$13,061,491</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>$2,354,205</td>\n",
       "      <td>1,911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>Biography,Comedy,Drama,Fantasy,Romance</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm0823330</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Steve Starkey</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>producer,assistant_director,editorial_department</td>\n",
       "      <td>tt0109830,tt0118884,tt1907668,tt0162222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Welcome to Marwen</td>\n",
       "      <td>$10,763,520</td>\n",
       "      <td>$13,061,491</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>$2,354,205</td>\n",
       "      <td>1,911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>Biography,Comedy,Drama,Fantasy,Romance</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm0823330</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Steve Starkey</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>producer,assistant_director,editorial_department</td>\n",
       "      <td>tt0109830,tt0118884,tt1907668,tt0162222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>The House</td>\n",
       "      <td>$25,584,504</td>\n",
       "      <td>$34,184,504</td>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>$8,724,795</td>\n",
       "      <td>3,134</td>\n",
       "      <td>$40,000,000</td>\n",
       "      <td>R</td>\n",
       "      <td>Comedy,Crime</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm0909629</td>\n",
       "      <td>writer</td>\n",
       "      <td>written by</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Enda Walsh</td>\n",
       "      <td>1967</td>\n",
       "      <td>\\N</td>\n",
       "      <td>writer,director,actor</td>\n",
       "      <td>tt11703050,tt0986233,tt0236157,tt21211282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>932</td>\n",
       "      <td>Gifted</td>\n",
       "      <td>$24,801,212</td>\n",
       "      <td>$43,046,590</td>\n",
       "      <td>Fox Searchlight</td>\n",
       "      <td>$446,380</td>\n",
       "      <td>56</td>\n",
       "      <td>$7,000,000</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>Drama</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm5537416</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Edwin Sherman</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>producer</td>\n",
       "      <td>tt3758280,tt2393799,tt3727750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>933</td>\n",
       "      <td>Kidnap</td>\n",
       "      <td>$30,971,040</td>\n",
       "      <td>$34,814,102</td>\n",
       "      <td>Aviron Pictures</td>\n",
       "      <td>$10,016,323</td>\n",
       "      <td>2,378</td>\n",
       "      <td>$21,000,000</td>\n",
       "      <td>R</td>\n",
       "      <td>Action,Crime,Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm5762850</td>\n",
       "      <td>cinematographer</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Souvik Basu</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>cinematographer,camera_department</td>\n",
       "      <td>tt10626906,tt23781422,tt10300662,tt5534436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>934</td>\n",
       "      <td>Kidnap</td>\n",
       "      <td>$30,971,040</td>\n",
       "      <td>$34,814,102</td>\n",
       "      <td>Aviron Pictures</td>\n",
       "      <td>$10,016,323</td>\n",
       "      <td>2,378</td>\n",
       "      <td>$21,000,000</td>\n",
       "      <td>R</td>\n",
       "      <td>Action,Crime,Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>nm11940155</td>\n",
       "      <td>editor</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Renjith Surendran</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>editor,editorial_department</td>\n",
       "      <td>tt13192140,tt21094962,tt15554854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>935</td>\n",
       "      <td>Split</td>\n",
       "      <td>$138,291,365</td>\n",
       "      <td>$278,454,358</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>$40,010,975</td>\n",
       "      <td>3,038</td>\n",
       "      <td>$9,000,000</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>Horror,Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>nm9962380</td>\n",
       "      <td>actor</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Daniel Valient</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>actor,writer,producer</td>\n",
       "      <td>tt18182248,tt23138450,tt13011756,tt16533132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>936 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0            originalTitle domestic_revenue world_revenue  \\\n",
       "0             0                 Super 30       $2,269,878   $24,701,637   \n",
       "1             1                 Ad Astra      $50,188,370  $127,461,872   \n",
       "2             2  The Art of Self-Defense       $2,410,914    $2,414,269   \n",
       "3             3        Welcome to Marwen      $10,763,520   $13,061,491   \n",
       "4             4        Welcome to Marwen      $10,763,520   $13,061,491   \n",
       "..          ...                      ...              ...           ...   \n",
       "931         931                The House      $25,584,504   $34,184,504   \n",
       "932         932                   Gifted      $24,801,212   $43,046,590   \n",
       "933         933                   Kidnap      $30,971,040   $34,814,102   \n",
       "934         934                   Kidnap      $30,971,040   $34,814,102   \n",
       "935         935                    Split     $138,291,365  $278,454,358   \n",
       "\n",
       "               distributor opening_revenue opening_theaters       budget  \\\n",
       "0    Reliance Big Pictures        $871,256              317          NaN   \n",
       "1    Twentieth Century Fox     $19,001,398            3,460  $90,000,000   \n",
       "2    Bleecker Street Media        $114,374                7          NaN   \n",
       "3       Universal Pictures      $2,354,205            1,911          NaN   \n",
       "4       Universal Pictures      $2,354,205            1,911          NaN   \n",
       "..                     ...             ...              ...          ...   \n",
       "931           Warner Bros.      $8,724,795            3,134  $40,000,000   \n",
       "932        Fox Searchlight        $446,380               56   $7,000,000   \n",
       "933        Aviron Pictures     $10,016,323            2,378  $21,000,000   \n",
       "934        Aviron Pictures     $10,016,323            2,378  $21,000,000   \n",
       "935     Universal Pictures     $40,010,975            3,038   $9,000,000   \n",
       "\n",
       "      MPAA                                    genres_x  ...  ordering  \\\n",
       "0      NaN                             Biography,Drama  ...         9   \n",
       "1    PG-13     Adventure,Drama,Mystery,Sci-Fi,Thriller  ...         9   \n",
       "2        R  Action,Comedy,Crime,Drama,Mystery,Thriller  ...         9   \n",
       "3    PG-13      Biography,Comedy,Drama,Fantasy,Romance  ...         9   \n",
       "4    PG-13      Biography,Comedy,Drama,Fantasy,Romance  ...         9   \n",
       "..     ...                                         ...  ...       ...   \n",
       "931      R                                Comedy,Crime  ...         9   \n",
       "932  PG-13                                       Drama  ...         9   \n",
       "933      R                       Action,Crime,Thriller  ...         9   \n",
       "934      R                       Action,Crime,Thriller  ...         9   \n",
       "935  PG-13                             Horror,Thriller  ...         4   \n",
       "\n",
       "         nconst         category         job  characters  \\\n",
       "0     nm0618898         producer    producer          \\N   \n",
       "1     nm1250070         producer    producer          \\N   \n",
       "2     nm3442546         producer    producer          \\N   \n",
       "3     nm0823330         producer    producer          \\N   \n",
       "4     nm0823330         producer    producer          \\N   \n",
       "..          ...              ...         ...         ...   \n",
       "931   nm0909629           writer  written by          \\N   \n",
       "932   nm5537416         producer    producer          \\N   \n",
       "933   nm5762850  cinematographer          \\N          \\N   \n",
       "934  nm11940155           editor          \\N          \\N   \n",
       "935   nm9962380            actor          \\N          \\N   \n",
       "\n",
       "              primaryName birthYear  deathYear  \\\n",
       "0        Sajid Nadiadwala      1966         \\N   \n",
       "1          Jeremy Kleiner        \\N         \\N   \n",
       "2    Stephanie Whonsetler        \\N         \\N   \n",
       "3           Steve Starkey        \\N         \\N   \n",
       "4           Steve Starkey        \\N         \\N   \n",
       "..                    ...       ...        ...   \n",
       "931            Enda Walsh      1967         \\N   \n",
       "932         Edwin Sherman        \\N         \\N   \n",
       "933           Souvik Basu        \\N         \\N   \n",
       "934     Renjith Surendran        \\N         \\N   \n",
       "935        Daniel Valient        \\N         \\N   \n",
       "\n",
       "                                    primaryProfession  \\\n",
       "0                            producer,writer,director   \n",
       "1                              producer,miscellaneous   \n",
       "2           production_manager,miscellaneous,producer   \n",
       "3    producer,assistant_director,editorial_department   \n",
       "4    producer,assistant_director,editorial_department   \n",
       "..                                                ...   \n",
       "931                             writer,director,actor   \n",
       "932                                          producer   \n",
       "933                 cinematographer,camera_department   \n",
       "934                       editor,editorial_department   \n",
       "935                             actor,writer,producer   \n",
       "\n",
       "                                  knownForTitles  \n",
       "0        tt7518786,tt2372222,tt8366590,tt7721946  \n",
       "1        tt2024544,tt1020072,tt4975722,tt7125860  \n",
       "2       tt6269368,tt10962368,tt7339248,tt4595186  \n",
       "3        tt0109830,tt0118884,tt1907668,tt0162222  \n",
       "4        tt0109830,tt0118884,tt1907668,tt0162222  \n",
       "..                                           ...  \n",
       "931    tt11703050,tt0986233,tt0236157,tt21211282  \n",
       "932                tt3758280,tt2393799,tt3727750  \n",
       "933   tt10626906,tt23781422,tt10300662,tt5534436  \n",
       "934             tt13192140,tt21094962,tt15554854  \n",
       "935  tt18182248,tt23138450,tt13011756,tt16533132  \n",
       "\n",
       "[936 rows x 29 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['world_revenue'] = movies_df.world_revenue.str.replace('$','',regex=True)\n",
    "movies_df['world_revenue'] = movies_df.world_revenue.str.replace(',','',regex=True)\n",
    "movies_df['world_revenue'] =  pd.to_numeric(movies_df['world_revenue'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[\"revenue_cat\"] = pd.cut(\n",
    "                    movies_df[\"world_revenue\"],\n",
    "                    bins=[0.0, 1.5, 3.0, 4.5, 6.0, np.inf],  #category for our world revenue 0.0 and 1.5 one group 1.5 to 3.0 another\n",
    "                    labels=[1,2,3,4,5]  #names\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set = None\n",
    "strat_test_set = None\n",
    "#we are using StratifiedShuffleSplit to create  split with the size of 80:20 and n_splits is \n",
    "# number of times the data needs to be sampled for test_size and data's are taken randomly at 42 \n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "#our group is movies_df[\"income_cat\"] so split function will split based on this category\n",
    "for train_index,test_index in split.split(movies_df, movies_df[\"revenue_cat\"]):\n",
    "    #since only for split we use movies_df[\"income_cat\"] we are droping from train and test split\n",
    "    strat_train_set = movies_df.loc[train_index].drop([\"revenue_cat\"],axis=1)\n",
    "    strat_test_set = movies_df.loc[test_index].drop([\"revenue_cat\"],axis=1)\n",
    "train_file_path = os.path.join(data_ingestion_config.ingested_train_dir,\n",
    "                                            file_name)\n",
    "\n",
    "test_file_path = os.path.join(data_ingestion_config.ingested_test_dir,\n",
    "                                        file_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "if strat_train_set is not None:\n",
    "    os.makedirs(data_ingestion_config.ingested_train_dir,exist_ok=True)\n",
    "    #logging.info(f\"Exporting training datset to file: [{train_file_path}]\")\n",
    "    strat_train_set.to_csv(train_file_path,index=False)\n",
    "\n",
    "if strat_test_set is not None:\n",
    "    os.makedirs(data_ingestion_config.ingested_test_dir, exist_ok= True)\n",
    "    #logging.info(f\"Exporting test dataset to file: [{test_file_path}]\")\n",
    "    strat_test_set.to_csv(test_file_path,index=False)\n",
    "\n",
    "\n",
    "data_ingestion_artifact = DataIngestionArtifact(train_file_path=train_file_path,\n",
    "        test_file_path=test_file_path,\n",
    "        is_ingested=True,\n",
    "        message=f\"Data ingestion completed successfully.\"\n",
    "        )  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataIngestionArtifact(train_file_path='artifacts/data_ingestion/train/main.csv', test_file_path='artifacts/data_ingestion/test/main.csv', is_ingested=True, message='Data ingestion completed successfully.')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ingestion_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artifacts/data_ingestion/train'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ingestion_config.ingested_train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = os.path.join(data_ingestion_config.ingested_train_dir,\n",
    "                                            file_name)\n",
    "\n",
    "test_file_path = os.path.join(data_ingestion_config.ingested_test_dir,\n",
    "                                        file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artifacts/data_ingestion/train/main.csv'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataIngestionArtifact(train_file_path='artifacts/data_ingestion/train/main.csv', test_file_path='artifacts/data_ingestion/test/main.csv', is_ingested=True, message='Data ingestion completed successfully.')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataIngestionArtifact(train_file_path=train_file_path,\n",
    "                test_file_path=test_file_path,\n",
    "                is_ingested=True,\n",
    "                message=f\"Data ingestion completed successfully.\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.DataIngestionArtifact"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "DataIngestionArtifact.train_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
